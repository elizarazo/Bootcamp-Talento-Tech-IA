{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Proceso de Decisión de Markov (MDP)\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "estados = ['A', 'B', 'C']\n",
        "acciones = ['izquierda', 'abajo']\n",
        "recompensas = np.random.randint(0,10,size=(len(estados),len(acciones)))\n",
        "print('recompensas',recompensas)\n",
        "\n",
        "#Función de transición aleatoria\n",
        "def transicion_aleatoria():\n",
        "    return np.random.choice(estados)\n",
        "\n",
        "#Generación de datos\n",
        "estado_actual = np.random.choice(estados)\n",
        "accion = np.random.choice(acciones)\n",
        "nuevo_estado = transicion_aleatoria()\n",
        "recompensa = recompensas[estados.index(estado_actual), acciones.index(accion)]\n",
        "\n",
        "print(\"Estado actual:\", estado_actual)\n",
        "print(\"Acción tomada:\", accion)\n",
        "print(\"Nuevo estado:\", nuevo_estado)\n",
        "print(\"Recompensa:\", recompensa)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v69UCBhm7ODD",
        "outputId": "ba4adf07-ca5d-49fa-ae64-fc77007d9f70"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recompensas [[5 1]\n",
            " [5 4]\n",
            " [8 6]]\n",
            "Estado actual: A\n",
            "Acción tomada: izquierda\n",
            "Nuevo estado: B\n",
            "Recompensa: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición de transiciones aleatorias\n",
        "def generar_transiciones(estados, acciones):\n",
        "    transiciones = {}\n",
        "    for estado in estados:\n",
        "        transiciones[estado] = {}\n",
        "        for accion in acciones:\n",
        "            probabilidades = np.random.rand(len(estados))  # Probabilidades aleatorias\n",
        "            probabilidades /= probabilidades.sum()  # Normalizar para que sumen 1\n",
        "            transiciones[estado][accion] = {nuevo_estado: prob for nuevo_estado, prob in zip(estados, probabilidades)}\n",
        "    return transiciones\n",
        "\n",
        "transiciones = generar_transiciones(estados, acciones)\n",
        "print(transiciones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO-9gElpEKgr",
        "outputId": "c336d8de-bf33-4d6f-b737-c0bb49967b29"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'A': {'izquierda': {'A': 0.5013102184008875, 'B': 0.4209757920515474, 'C': 0.07771398954756498}, 'abajo': {'A': 0.005565797773062945, 'B': 0.25297855996959245, 'C': 0.7414556422573446}}, 'B': {'izquierda': {'A': 0.41997893463477626, 'B': 0.42894118076107757, 'C': 0.15107988460414606}, 'abajo': {'A': 0.3496211726751686, 'B': 0.30812943111488506, 'C': 0.34224939620994627}}, 'C': {'izquierda': {'A': 0.25146703195456155, 'B': 0.21287666913456385, 'C': 0.5356562989108745}, 'abajo': {'A': 0.3597205922146921, 'B': 0.3575041281810375, 'C': 0.2827752796042703}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clase MDP\n",
        "class MDP:\n",
        "    def __init__(self, estados, acciones, transiciones, recompensas):\n",
        "        self.estados = estados\n",
        "        self.acciones = acciones\n",
        "        self.transiciones = transiciones\n",
        "        self.recompensas = recompensas\n",
        "\n",
        "# Crear la instancia del MDP\n",
        "mdp = MDP(estados, acciones, transiciones, recompensas)\n",
        "\n",
        "def calcular_valor_estado(mdp, gamma=0.9, theta=0.01):\n",
        "    valores = {estado: 0 for estado in mdp.estados}\n",
        "    while True:\n",
        "        delta = 0\n",
        "        for estado in mdp.estados:\n",
        "            valor_previo = valores[estado]\n",
        "            valor_nuevo = 0\n",
        "            for accion in mdp.acciones:\n",
        "                if estado in mdp.transiciones and accion in mdp.transiciones[estado]:\n",
        "                    for nuevo_estado in mdp.transiciones[estado][accion]:  # Iterar solo sobre los estados posibles\n",
        "                        prob_transicion = mdp.transiciones[estado][accion].get(nuevo_estado, 0)\n",
        "                        recompensa = mdp.recompensas[mdp.estados.index(estado)][mdp.acciones.index(accion)]\n",
        "                        valor_nuevo += prob_transicion * (recompensa + gamma * valores[nuevo_estado])\n",
        "            valores[estado] = np.clip(valor_nuevo, -1e10, 1e10)  # Limitar el rango de valores\n",
        "            delta = max(delta, abs(valor_previo - valores[estado]))\n",
        "        if delta < theta:\n",
        "            break\n",
        "    return valores\n",
        "\n",
        "#Ejemplos de uso\n",
        "valores_estados = calcular_valor_estado(mdp)\n",
        "print('Valores de los estados:', valores_estados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxiLyKHJ8a7D",
        "outputId": "2277d1b6-5c86-4ad0-e293-7715e4f4d2dd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores de los estados: {'A': 10000000000.0, 'B': 10000000000.0, 'C': 10000000000.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Propiedades de Markov\n",
        "#Escribe una función para verificar si un MDP dado cumple con la propiedad de Markov\n",
        "def verificar_propiedad_markov(mdp):\n",
        "    for estado in mdp.estados:\n",
        "        for accion in mdp.acciones:\n",
        "            suma_probabilidades = sum(mdp.transiciones[estado][accion].values())\n",
        "            if not np.isclose(suma_probabilidades, 1.0):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "#Ejemplo de uso\n",
        "print('Cumple con la propiedad de Markov:', verificar_propiedad_markov(mdp))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYalZj7YZW6-",
        "outputId": "8bd06331-c053-4095-9915-0ce6ddf61578"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumple con la propiedad de Markov: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(mdp.recompensas))\n",
        "print(mdp.recompensas)\n",
        "print(mdp.transiciones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keela3gycwBy",
        "outputId": "481f1aa8-0b74-45fd-954f-af4d9f8c05b3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[[5 1]\n",
            " [5 4]\n",
            " [8 6]]\n",
            "{'A': {'izquierda': {'A': 0.5013102184008875, 'B': 0.4209757920515474, 'C': 0.07771398954756498}, 'abajo': {'A': 0.005565797773062945, 'B': 0.25297855996959245, 'C': 0.7414556422573446}}, 'B': {'izquierda': {'A': 0.41997893463477626, 'B': 0.42894118076107757, 'C': 0.15107988460414606}, 'abajo': {'A': 0.3496211726751686, 'B': 0.30812943111488506, 'C': 0.34224939620994627}}, 'C': {'izquierda': {'A': 0.25146703195456155, 'B': 0.21287666913456385, 'C': 0.5356562989108745}, 'abajo': {'A': 0.3597205922146921, 'B': 0.3575041281810375, 'C': 0.2827752796042703}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Propiedades de recompensa\n",
        "#Escribe una función para calcular la\n",
        "#recompensa promedio por acción en un MDP.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def calcular_recompensa_promedio(mdp):\n",
        "    recompensa_total = 0\n",
        "    total_acciones = 0\n",
        "    for estado in mdp.estados:\n",
        "        for accion in mdp.acciones:\n",
        "            for nuevo_estado in mdp.transiciones[estado][accion]:\n",
        "                indice_estado = mdp.estados.index(estado)\n",
        "                indice_accion = mdp.acciones.index(accion)\n",
        "                recompensa_total += mdp.recompensas[indice_estado, indice_accion]\n",
        "                total_acciones += 1\n",
        "    return recompensa_total / total_acciones if total_acciones > 0 else 0\n",
        "\n",
        "# Ejemplo de uso\n",
        "print('Recompensa promedio por acción:', calcular_recompensa_promedio(mdp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WJKrhwqaaHu",
        "outputId": "6e7105e6-5b16-4228-8b45-825fe758bb3e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recompensa promedio por acción: 4.833333333333333\n"
          ]
        }
      ]
    }
  ]
}