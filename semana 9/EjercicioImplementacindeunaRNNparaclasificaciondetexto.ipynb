{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNV4XHAurC5q",
        "outputId": "86a8ab39-dccc-4e76-da18-0abee2b22347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PhraseId  SentenceId                                             Phrase  \\\n",
            "0         1           1  A series of escapades demonstrating the adage ...   \n",
            "1         2           1  A series of escapades demonstrating the adage ...   \n",
            "2         3           1                                           A series   \n",
            "3         4           1                                                  A   \n",
            "4         5           1                                             series   \n",
            "\n",
            "   Sentiment  \n",
            "0          1  \n",
            "1          2  \n",
            "2          2  \n",
            "3          2  \n",
            "4          2  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import csv  # Importar el módulo csv\n",
        "\n",
        "import zipfile\n",
        "\n",
        "\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "zip_file_path = r'/content/train.tsv.zip'  # Replace 'actual_file_name.zip' with the correct filename\n",
        "extract_to_path = r'/content/'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "\n",
        "#importing dataset\n",
        "# Usar on_bad_lines para manejar líneas mal formadas\n",
        "#df = pd.read_csv('train.tsv', delimiter=',', quotechar='\"', on_bad_lines='skip', encoding='utf-8', low_memory=False, quoting=csv.QUOTE_MINIMAL)\n",
        "df = pd.read_csv(extract_to_path + '/train.tsv', sep='\\t')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9n2pVMGfE4f",
        "outputId": "c20bace1-a1b1-4bf6-a467-5507e78a8870"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            PhraseId     SentenceId      Sentiment\n",
            "count  156060.000000  156060.000000  156060.000000\n",
            "mean    78030.500000    4079.732744       2.063578\n",
            "std     45050.785842    2502.764394       0.893832\n",
            "min         1.000000       1.000000       0.000000\n",
            "25%     39015.750000    1861.750000       2.000000\n",
            "50%     78030.500000    4017.000000       2.000000\n",
            "75%    117045.250000    6244.000000       3.000000\n",
            "max    156060.000000    8544.000000       4.000000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 156060 entries, 0 to 156059\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   PhraseId    156060 non-null  int64 \n",
            " 1   SentenceId  156060 non-null  int64 \n",
            " 2   Phrase      156060 non-null  object\n",
            " 3   Sentiment   156060 non-null  int64 \n",
            "dtypes: int64(3), object(1)\n",
            "memory usage: 4.8+ MB\n"
          ]
        }
      ],
      "source": [
        "#Checking Dataset Description\n",
        "print(df.describe())\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DMdUMVMfMBV",
        "outputId": "fd949a53-ddc7-4de8-ec0e-f13e7355e6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PhraseId', 'SentenceId', 'Phrase', 'Sentiment'], dtype='object')\n",
            "Total :\n",
            " Sentiment\n",
            "2    79582\n",
            "3    32927\n",
            "1    27273\n",
            "4     9206\n",
            "0     7072\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check the column names in your DataFrame\n",
        "print(df.columns)\n",
        "\n",
        "#Sentiment count\n",
        "print(\"Total :\\n\",df['Sentiment'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4ia-5cyffcT0"
      },
      "outputs": [],
      "source": [
        "# Creating a new column with a 'for loop and if statement' from the Sentiment column\n",
        "\n",
        "Sentiment_phrase =[]\n",
        "\n",
        "for row in df['Sentiment']:\n",
        "    if row == 0:\n",
        "        Sentiment_phrase.append('negative')\n",
        "    elif row == 1:\n",
        "        Sentiment_phrase.append('somewhat negative')\n",
        "    elif row == 2:\n",
        "        Sentiment_phrase.append('neutral')\n",
        "    elif row == 3:\n",
        "        Sentiment_phrase.append('somewhat positive')\n",
        "    elif row == 4:\n",
        "        Sentiment_phrase.append('positive')\n",
        "    else:\n",
        "        Sentiment_phrase.append('Failed')\n",
        "\n",
        "\n",
        "df['Sentiment_phrase'] = Sentiment_phrase\n",
        "\n",
        "review = []\n",
        "sentences = list(df['Phrase'])\n",
        "for sen in sentences:\n",
        "    review.append(sen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_QXksi5ofxEC"
      },
      "outputs": [],
      "source": [
        "#Creación de etiquetas\n",
        "import numpy as np\n",
        "\n",
        "labels = df['Sentiment_phrase']\n",
        "labels = np.array(list(map(lambda x: 4 if x==\"positive\"\n",
        "                           else 3 if x=='somewhat positive'\n",
        "                           else 2 if x=='neutral'\n",
        "                           else 1 if x=='somewhat negative'\n",
        "                           else 0 , labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RZcPO95jghWv"
      },
      "outputs": [],
      "source": [
        "#División de datos de entrenamiento y prueba\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences, test_sentences, train_labels, test_labels = train_test_split(review, labels, test_size=0.20, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "snJ-9n6NhLSs"
      },
      "outputs": [],
      "source": [
        "# Preparar los datos\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_sentences, test_sentences, train_labels, test_labels = train_test_split(review, labels, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gERkOx4yhNtq"
      },
      "outputs": [],
      "source": [
        "# Parámetros de configuración\n",
        "vocab_size = 10000\n",
        "max_length = 120\n",
        "embedding_dim = 16\n",
        "trunc_type='post'\n",
        "oov_tok = \"<OOV>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j86ClvVGipOd",
        "outputId": "da9afb40-da47-4aec-85b1-4177e9f0098a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RcBzP6R7hd2D"
      },
      "outputs": [],
      "source": [
        "#tokenización y acolchado de secuencias\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#initialize the tokenizer class\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "\n",
        "#Generate the word index dictionary for the training sentences\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "#Generate and pad the training sequences\n",
        "sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "#Generate and pad the test sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_padded = pad_sequences(test_sequences,maxlen=max_length, truncating=trunc_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-v1rLrv1joVA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Construcción del modelo\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    LSTM(32),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8_sAneekMlL",
        "outputId": "cc82f73e-fb09-4ec6-8e8c-4744a95ff042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1435/3122\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:23\u001b[0m 121ms/step - accuracy: 0.1769 - loss: -111.0269"
          ]
        }
      ],
      "source": [
        "#Construcción y entrenamiento del modelo\n",
        "#setup the training parameters\n",
        "#model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)  # Experiment with learning rate\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model (assuming you have defined X_train and y_train)\n",
        "# ...\n",
        "history = model.fit(padded,\n",
        "                    train_labels, epochs=20, batch_size=32,\n",
        "                    validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model (assuming you have defined X_test and y_test)\n",
        "# ...\n",
        "loss, accuracy = model.evaluate(test_test_labels, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "\n",
        "# Print the model summary\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX6zz3spkldr"
      },
      "outputs": [],
      "source": [
        "#train the model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "history = model.fit(padded,\n",
        "                    train_labels,\n",
        "                    epochs=num_epochs,\n",
        "                    validation_data=(test_padded, test_labels))\n",
        "\n",
        "# Graficar el historial de entrenamiento\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehBz7ArL9zZd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, accuracy_score\n",
        "\n",
        "# Obtener las predicciones del modelo sobre el conjunto de prueba\n",
        "predictions = model.predict(test_padded)\n",
        "predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "# Calcular la accuracy\n",
        "accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "\n",
        "# Calcular el F1 score\n",
        "f1 = f1_score(test_labels, predicted_labels)\n",
        "\n",
        "# Crear la matriz de confusión\n",
        "cm = confusion_matrix(test_labels, predicted_labels)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])\n",
        "\n",
        "# Graficar la matriz de confusión\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "disp.plot(ax=ax)\n",
        "plt.show()\n",
        "\n",
        "# Mostrar la accuracy y el F1 score\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQhBf9PN_BPz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Obtener las probabilidades de las predicciones\n",
        "y_prob = model.predict(test_padded).ravel()\n",
        "\n",
        "# Calcular la curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(test_labels, y_prob, pos_label=1)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Graficar la curva ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "print(f\"AUC: {roc_auc:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5zwxfmR_f75"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Obtener las predicciones del modelo\n",
        "y_pred = (model.predict(test_padded) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calcular los errores como la diferencia entre las etiquetas verdaderas y las predicciones\n",
        "errors = np.array(test_labels) - np.array(y_pred).flatten()\n",
        "\n",
        "# Crear el histograma de errores con barras más delgadas\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(errors, kde=True, bins=30)\n",
        "plt.xlabel('Prediction Outcome')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Prediction Errors')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}