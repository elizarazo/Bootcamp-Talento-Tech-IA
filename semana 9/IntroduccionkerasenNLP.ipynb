{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import keras\n","frases = [\n","    'Hola mundo',\n","    'Hola a todos',\n","    'Hola a todo el mundo'\n","]"],"metadata":{"id":"DeN2bBNInBv_","executionInfo":{"status":"ok","timestamp":1722930448865,"user_tz":-120,"elapsed":9423,"user":{"displayName":"edgar lizarazo","userId":"04576770117662547959"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Generare el diccionario de token"],"metadata":{"id":"G25jbbWpqKd0"}},{"cell_type":"code","source":["#Generare el diccionario de token\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","\n","tokenizer = Tokenizer(num_words=10)\n","tokenizer.fit_on_texts(frases)\n","word_index = tokenizer.word_index\n","print('word_index', word_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7II1O8oJUX2s","executionInfo":{"status":"ok","timestamp":1722930448869,"user_tz":-120,"elapsed":46,"user":{"displayName":"edgar lizarazo","userId":"04576770117662547959"}},"outputId":"b970be00-d348-4c76-f2a4-68ce0ee06f7c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["word_index {'hola': 1, 'mundo': 2, 'a': 3, 'todos': 4, 'todo': 5, 'el': 6}\n"]}]},{"cell_type":"markdown","source":["Generación de secuencia tokenizada"],"metadata":{"id":"i55aQxvWqUb2"}},{"cell_type":"code","source":["#Generación de secuencia tokenizadas\n","secuencias = tokenizer.texts_to_sequences(frases)\n","print('secuencias', secuencias)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IHfWr2PgVrFU","executionInfo":{"status":"ok","timestamp":1722930448870,"user_tz":-120,"elapsed":42,"user":{"displayName":"edgar lizarazo","userId":"04576770117662547959"}},"outputId":"8e25c708-205a-4100-a850-8f44efff4e85"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["secuencias [[1, 2], [1, 3, 4], [1, 3, 5, 6, 2]]\n"]}]},{"cell_type":"markdown","source":["Rellena las secuencias a un longitud uniforme"],"metadata":{"id":"NMl-6uokqb26"}},{"cell_type":"code","source":["#Rellena las secuencias a un longitud uniforme\n","relleno = keras.preprocessing.sequence.pad_sequences(secuencias)\n","print('relleno', relleno)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yim85tn8V5W7","executionInfo":{"status":"ok","timestamp":1722930448870,"user_tz":-120,"elapsed":33,"user":{"displayName":"edgar lizarazo","userId":"04576770117662547959"}},"outputId":"4348bef0-595a-4ee3-8424-ee2af3d07dba"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["relleno [[0 0 0 1 2]\n"," [0 0 1 3 4]\n"," [1 3 5 6 2]]\n"]}]},{"cell_type":"markdown","source":["Realizando cambios al código para observar resultados obtenidos"],"metadata":{"id":"pFe6Be1fqgww"}},{"cell_type":"code","source":["#Realizando cambios al código para observar resultados obtenidos\n","import keras\n","\n","frases = [\n","    'Hola mundo',\n","    'Hola a todos',\n","    'Hola a todo el mundo',\n","    'Buen día, ¿cómo estás hoy?'\n","]\n","\n","#Generare el diccionario de token\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","tokenizer = Tokenizer(num_words=10)\n","tokenizer.fit_on_texts(frases)\n","word_index = tokenizer.word_index\n","print('word_index', word_index)\n","\n","#Generación de secuencia tokenizadas\n","secuencias = tokenizer.texts_to_sequences(frases)\n","print('secuencias', secuencias)\n","\n","#Rellena las secuencias a un longitud uniforme\n","relleno = keras.preprocessing.sequence.pad_sequences(secuencias)\n","print('relleno', relleno)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tAQEOeFZWBfD","executionInfo":{"status":"ok","timestamp":1722930448871,"user_tz":-120,"elapsed":29,"user":{"displayName":"edgar lizarazo","userId":"04576770117662547959"}},"outputId":"eb686bd0-3408-4762-c593-5166f8038338"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["word_index {'hola': 1, 'mundo': 2, 'a': 3, 'todos': 4, 'todo': 5, 'el': 6, 'buen': 7, 'día': 8, '¿cómo': 9, 'estás': 10, 'hoy': 11}\n","secuencias [[1, 2], [1, 3, 4], [1, 3, 5, 6, 2], [7, 8, 9]]\n","relleno [[0 0 0 1 2]\n"," [0 0 1 3 4]\n"," [1 3 5 6 2]\n"," [0 0 7 8 9]]\n"]}]},{"cell_type":"markdown","source":["\n","\n","```\n","Realizando cambios al código para observar resultados obtenidos```\n","\n"],"metadata":{"id":"LkKAayAbqt7J"}},{"cell_type":"code","source":["#Realizando cambios al código para observar resultados obtenidos\n","import keras\n","\n","frases = [\n","    'Hola mundo',\n","    'Hola a todos',\n","    'Hola a todo el mundo',\n","    'Buen día, ¿cómo estás hoy?'\n","]\n","\n","#Generare el diccionario de token\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","tokenizer = Tokenizer(num_words=10, oov_token = \"<OOV>\" )\n","tokenizer.fit_on_texts(frases)\n","word_index = tokenizer.word_index\n","print('word_index', word_index)\n","\n","#Generación de secuencia tokenizadas\n","secuencias = tokenizer.texts_to_sequences(frases)\n","print('secuencias', secuencias)\n","\n","#Rellena las secuencias a un longitud uniforme\n","relleno = keras.preprocessing.sequence.pad_sequences(secuencias)\n","print('relleno', relleno)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QnX063wOXh6l","executionInfo":{"status":"ok","timestamp":1722930448871,"user_tz":-120,"elapsed":23,"user":{"displayName":"edgar lizarazo","userId":"04576770117662547959"}},"outputId":"fab7b14b-fa8b-4892-d542-5ab9da930d41"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["word_index {'<OOV>': 1, 'hola': 2, 'mundo': 3, 'a': 4, 'todos': 5, 'todo': 6, 'el': 7, 'buen': 8, 'día': 9, '¿cómo': 10, 'estás': 11, 'hoy': 12}\n","secuencias [[2, 3], [2, 4, 5], [2, 4, 6, 7, 3], [8, 9, 1, 1, 1]]\n","relleno [[0 0 0 2 3]\n"," [0 0 2 4 5]\n"," [2 4 6 7 3]\n"," [8 9 1 1 1]]\n"]}]},{"cell_type":"markdown","source":["Realizando cambios al código para observar resultados obtenidos"],"metadata":{"id":"IsJOnd_brFi-"}},{"cell_type":"code","source":["#Realizando cambios al código para observar resultados obtenidos\n","import keras\n","\n","frases = [\n","    'Hola mundo',\n","    'Hola a todos',\n","    'Hola a todo el mundo',\n","    'Buen día, ¿cómo estás hoy?'\n","]\n","\n","#Generare el diccionario de token\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","tokenizer = Tokenizer(num_words=10, oov_token = \"<OOV>\" )\n","tokenizer.fit_on_texts(frases)\n","word_index = tokenizer.word_index\n","print('word_index', word_index)\n","\n","#Generación de secuencia tokenizadas\n","secuencias = tokenizer.texts_to_sequences(frases)\n","print('secuencias', secuencias)\n","\n","#Rellena las secuencias a un longitud uniforme\n","relleno = keras.preprocessing.sequence.pad_sequences(secuencias,\n","                                                     padding = 'post',\n","                                                     truncating = 'post')\n","print('relleno', relleno)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r07GejuOYkwQ","executionInfo":{"status":"ok","timestamp":1722930448872,"user_tz":-120,"elapsed":19,"user":{"displayName":"edgar lizarazo","userId":"04576770117662547959"}},"outputId":"a9b31ae2-4541-4021-f254-d95f55a7cccf"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["word_index {'<OOV>': 1, 'hola': 2, 'mundo': 3, 'a': 4, 'todos': 5, 'todo': 6, 'el': 7, 'buen': 8, 'día': 9, '¿cómo': 10, 'estás': 11, 'hoy': 12}\n","secuencias [[2, 3], [2, 4, 5], [2, 4, 6, 7, 3], [8, 9, 1, 1, 1]]\n","relleno [[2 3 0 0 0]\n"," [2 4 5 0 0]\n"," [2 4 6 7 3]\n"," [8 9 1 1 1]]\n"]}]}]}